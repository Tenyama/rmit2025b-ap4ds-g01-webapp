{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Assignment 2: Milestone I Natural Language Processing**\n",
    "## **Task 2 & 3**\n",
    "#### **Student Name**:\n",
    "#### **Student ID**:\n",
    "\n",
    "\n",
    "**Environment**: Python 3 and Jupyter notebook\n",
    "\n",
    "**Libraries used**: \n",
    "* pandas\n",
    "* numpy\n",
    "* collections.Counter\n",
    "* sklearn.feature_extraction.text.CountVectorizer\n",
    "* sklearn.feature_extraction.text.TfidfVectorizer\n",
    "* gensim.models.KeyedVectors\n",
    "* gensim.scripts.glove2word2vec.glove2word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "\n",
    "The first stage of the notebook addresses **Task 2: Generating Feature Representations** from Milestone 1 of the assignment. The goal is to convert the cleaned reviews from Task 1 into **numerical representations** that can be directly used by machine learning models for classification.  \n",
    "\n",
    "Specifically, I implement two categories of representations:  \n",
    "\n",
    "- **Bag-of-Words (BoW)** – Each review is converted into a sparse vector of token counts using the curated vocabulary built in Task 1. This frequency-based representation is saved in count_vectors.txt.\n",
    "- **Embedding-based Representations** – Each review is encoded using pretrained FastText embeddings (cc.en.300.vec), with two variants:\n",
    "  - **Unweighted average embeddings** – All known tokens contribute equally to the final review vector.\n",
    "  - **TF-IDF weighted embeddings** – Tokens are weighted by their inverse document frequency (IDF) to emphasize more informative words.\n",
    "\n",
    "By the end of this stage, I obtain multiple complementary feature representations of the reviews. These representations capture both surface-level token frequencies and deeper semantic meaning, providing the foundation for classification experiments in Task 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy import sparse\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Generating Feature Representations for Clothing Items Reviews\n",
    "\n",
    "With the preprocessing completed in Task 1, I now move on to generating feature representations of the reviews.  \n",
    "The goal of this step is to transform the cleaned text into numerical formats that can be used by machine learning models in Task 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load Processed Data\n",
    "\n",
    "Before I start building feature representations, I need to load the output from Task 1. The file `processed.csv` contains the cleaned and tokenized reviews that I generated earlier. From this file, I focus on the `Review Text` column, which holds the processed reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will convert it into a list of strings so it can be directly used in the different representation methods that follow in Task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of reviews:\n",
      "['high hopes wanted work initially petite usual found outrageously fact zip reordered petite medium half nicely bottom half tight layer cheap net layers imo major design flaw net layer sewn directly zipper', 'jumpsuit fun flirty fabulous time compliments', 'shirt due adjustable front tie length leggings sleeveless pairs cardigan shirt', 'tracy reese dresses petite feet tall brand pretty package lot skirt long full overwhelmed frame stranger alterations shortening skirt embellishment garment idea style work returned', 'basket hte person store pick teh pale hte gorgeous turns prefectly baggy hte xs hte bummer petite decided ejans pants skirts oops']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"t1_outputs/processed.csv\")\n",
    "df = df.dropna(subset=[\"Review Text\"])\n",
    "df = df[df[\"Review Text\"].str.strip().astype(bool)]\n",
    "reviews = df[\"Review Text\"].astype(str).tolist()\n",
    "\n",
    "print(\"Head of reviews:\")\n",
    "print(reviews[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I load the vocabulary file that I created in Task 1.  \n",
    "\n",
    "The file `vocab.txt` stores all valid tokens from the processed reviews, each mapped to a unique integer index. This mapping is essential because it ensures that every feature representation I build in Task 2 will use a **consistent and reproducible index space**.  \n",
    "\n",
    "Here, I read the file line by line, split each entry into the token and its index, and store them in a Python dictionary called `vocab`. This dictionary will serve as the reference for constructing bag-of-words vectors and other feature encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Head of vocab:\n",
      "a-cup: 0\n",
      "a-flutter: 1\n",
      "a-frame: 2\n",
      "a-kind: 3\n",
      "a-line: 4\n"
     ]
    }
   ],
   "source": [
    "with open(\"t1_outputs/vocab.txt\", \"r\") as f:\n",
    "    vocab_lines = f.readlines()\n",
    "\n",
    "vocab = {line.split(\":\")[0]: int(line.strip().split(\":\")[1]) for line in vocab_lines}\n",
    "\n",
    "print(\"\\nHead of vocab:\")\n",
    "for i, (word, idx) in enumerate(vocab.items()):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    print(f\"{word}: {idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Bag-of-Words Model: Count Vector Representation\n",
    "\n",
    "I begin by generating the **bag-of-words (BoW) representation** for each review. This method transforms each review into a sparse vector where: \n",
    "- The **index** corresponds to a token from the vocabulary created in Task 1.  \n",
    "- The **value** represents how many times that token appears in the review.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CountVectorizer using fixed vocab\n",
    "vectorizer = CountVectorizer(vocabulary=vocab)\n",
    "X_counts = vectorizer.fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Load FastText Word Vectors\n",
    "\n",
    "In this step, I load a pre-trained word embedding model to support the construction of vector-based representations for each review in later sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding model used here is **FastText** (`cc.en.300.vec`), which maps each word to a dense 300-dimensional vector based on how it appears in a wide range of real-world text. One key advantage of FastText is its ability to handle **out-of-vocabulary (OOV)** words — that is, words not seen during training. \n",
    "\n",
    "It does this by breaking words into smaller overlapping sequences of characters called **n-grams** (\"dress\" contains trigrams like \"dre\", \"res\", \"ess\"). This means even if a word is misspelled, rare, or completely new, FastText can still generate a meaningful embedding based on its subword structure — an important feature when working with noisy or user-generated text like product reviews.\n",
    "\n",
    "\n",
    "The embedding file is already in a compatible `.vec` format, so I load it directly using `gensim`'s `KeyedVectors`. Once loaded, each word can be queried to retrieve its vector. These vectors will be used in the next stages to build:\n",
    "- **Unweighted document vectors**: average of all word vectors in a review.\n",
    "- **Weighted document vectors**: average of word vectors weighted by their TF-IDF score.\n",
    "\n",
    "This setup allows each review to be numerically represented in a form suitable for downstream classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 300\n",
      "Sample vector for 'quality': [ 0.0416  0.0178  0.0021  0.0199 -0.0519]\n"
     ]
    }
   ],
   "source": [
    "# Load FastText .vec file directly\n",
    "ft_model = KeyedVectors.load_word2vec_format(\"embedding_model/cc.en.300.vec\", binary=False)\n",
    "embedding_dim = ft_model.vector_size\n",
    "\n",
    "print(\"Embedding dimension:\", embedding_dim)\n",
    "print(\"Sample vector for 'quality':\", ft_model['quality'][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Tokenization Consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For feature extraction methods like Bag-of-Words and embeddings, I need to re-tokenize the text into word lists to ensure correct vocabulary matching and vector lookup. I will re-tokenize the reviews using the same regex pattern defined in Task 1. This guarantees alignment with the vocabulary and preprocessing applied earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = re.compile(r\"[a-zA-Z]+(?:[-'][a-zA-Z]+)?\") \n",
    "\n",
    "def tokenize(text): \n",
    "    tokens = tokenizer.findall(text.lower()) \n",
    "    clean_tokens = [t.strip(\"-'\") for t in tokens] # remove trailing punctuation if needed \n",
    "    return clean_tokens \n",
    "\n",
    "tokenized_reviews = [tokenize(r) for r in reviews] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 OOV Diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess how well the FastText model covers the dataset vocabulary, I calculate the out-of-vocabulary (OOV) rate across all tokens. This helps identify whether any significant preprocessing adjustments are needed before embedding lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText OOV Coverage: {'total_tokens': 355505, 'covered_tokens': 354155, 'coverage_pct': 99.62}\n"
     ]
    }
   ],
   "source": [
    "def compute_coverage(token_lists, model):\n",
    "    total = sum(len(toks) for toks in token_lists)\n",
    "    known = sum(sum(1 for tok in toks if tok in model) for toks in token_lists)\n",
    "    return {\n",
    "        \"total_tokens\": total,\n",
    "        \"covered_tokens\": known,\n",
    "        \"coverage_pct\": round(100 * known / total, 2)\n",
    "    }\n",
    "\n",
    "coverage = compute_coverage(tokenized_reviews, ft_model)\n",
    "print(\"FastText OOV Coverage:\", coverage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FastText model achieves a coverage of **99.62%**, leaving only **0.38%** of tokens unmatched. To ensure that the remaining unmatched tokens do not significantly impact downstream results, I inspect the OOV cases more closely before deciding whether additional handling is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top OOV tokens: [('pilcro', 267), (\"would've\", 83), ('xxsp', 77), (\"retailer's\", 56), (\"could've\", 38), (\"model's\", 35), ('pxs', 34), ('cartonnier', 23), ('true-to', 21), (\"should've\", 19)]\n",
      "All missing tokens:\n",
      "ejans: 2\n",
      "would've: 83\n",
      "could've: 38\n",
      "eptite: 3\n",
      "should've: 19\n",
      "square-apple: 2\n",
      "cami's: 3\n",
      "swtr: 5\n",
      "that'll: 2\n",
      "xxsp: 77\n",
      "pants-they: 2\n",
      "pilcro: 267\n",
      "woman's: 9\n",
      "xs-s: 13\n",
      "retailer's: 56\n",
      "pxs: 34\n",
      "maternity-ish: 8\n",
      "maternity-esque: 2\n",
      "season's: 4\n",
      "as-pictured: 3\n",
      "xspetite: 16\n",
      "peek-a: 7\n",
      "fit-and: 7\n",
      "valentine's: 5\n",
      "cartonnier: 23\n",
      "true-to: 21\n",
      "model's: 35\n",
      "camisol: 3\n",
      "denimy: 2\n",
      "and-go: 3\n",
      "husband's: 11\n",
      "skinny's: 3\n",
      "moulinette: 9\n",
      "sweatercoat: 5\n",
      "d-dd: 7\n",
      "compliements: 2\n",
      "fit's: 5\n",
      "dind't: 16\n",
      "d's: 4\n",
      "xs's: 2\n",
      "flattrering: 2\n",
      "brother's: 5\n",
      "lot's: 2\n",
      "canvas-y: 2\n",
      "lyocel: 2\n",
      "liekd: 2\n",
      "pettie: 3\n",
      "evanthe: 3\n",
      "floreat: 14\n",
      "charlie's: 4\n",
      "grandma's: 4\n",
      "above-the: 3\n",
      "deletta: 19\n",
      "x-s: 3\n",
      "maxi's: 3\n",
      "higher-waisted: 2\n",
      "pxxs: 14\n",
      "dress's: 6\n",
      "seafolly: 7\n",
      "lnever: 2\n",
      "maeve's: 5\n",
      "stevies: 12\n",
      "non-petite: 6\n",
      "reviewer's: 10\n",
      "mother's: 13\n",
      "day's: 2\n",
      "chrolox: 2\n",
      "levi's: 4\n",
      "fabric's: 4\n",
      "did't: 2\n",
      "arty-looking: 2\n",
      "mom's: 4\n",
      "t'shirt: 2\n",
      "child's: 6\n",
      "collector's: 2\n",
      "xxsmall: 2\n",
      "mom-bod: 2\n",
      "pilcros: 12\n",
      "pilcro's: 4\n",
      "s-m: 4\n",
      "neira: 4\n",
      "daughter's: 10\n",
      "size-i: 2\n",
      "peite: 4\n",
      "sweater-coat: 2\n",
      "tailor-fitted: 2\n",
      "xl's: 3\n",
      "dryel: 3\n",
      "eptites: 2\n",
      "lwait: 2\n",
      "a-symmetric: 2\n",
      "t-neck: 5\n",
      "anyone's: 6\n",
      "lightwei: 2\n",
      "side-zipper: 2\n",
      "embroiding: 3\n",
      "tyhlo: 2\n",
      "ombr: 5\n",
      "amterial: 3\n",
      "antrho: 8\n",
      "shirt's: 3\n",
      "blouse-y: 3\n",
      "flowier: 2\n",
      "everyone's: 4\n",
      "children's: 2\n",
      "derri: 5\n",
      "a-lines: 2\n",
      "rec'd: 2\n",
      "souers: 2\n",
      "falttering: 8\n",
      "law's: 2\n",
      "corodorys: 2\n",
      "niece's: 2\n",
      "sister's: 6\n",
      "light-to: 2\n",
      "pilco: 8\n",
      "jacket's: 2\n",
      "y'all: 2\n",
      "double-v: 2\n",
      "l-xl: 2\n",
      "sacklike: 4\n",
      "arm-holes: 3\n",
      "v's: 2\n",
      "fit-wise: 2\n",
      "knit-like: 2\n",
      "winter's: 2\n",
      "spetite: 2\n",
      "eprson: 2\n",
      "retailerpolgie: 4\n",
      "women's: 8\n",
      "size-small: 2\n",
      "ann's: 2\n",
      "gauzey: 2\n",
      "tenty: 2\n",
      "endora: 2\n",
      "fetherston: 2\n",
      "pop-back: 2\n",
      "sale-on: 2\n",
      "top's: 4\n",
      "undernea: 2\n",
      "manufacturer's: 4\n",
      "ag's: 2\n",
      "llonger: 2\n",
      "kedia: 2\n",
      "girl's: 2\n",
      "a-cup: 2\n",
      "over-shirt: 3\n",
      "paquerette: 3\n",
      "pilcos: 2\n",
      "pj's: 5\n",
      "coh's: 2\n",
      "jean's: 3\n",
      "popback: 2\n",
      "sweater's: 5\n",
      "petities: 2\n",
      "under-slip: 2\n",
      "nephew's: 2\n",
      "maternity-like: 3\n",
      "stevie's: 7\n",
      "poncho-like: 2\n",
      "cehst: 2\n",
      "unflatering: 2\n",
      "bra-straps: 2\n",
      "balloony: 3\n",
      "money's: 2\n",
      "petitte: 2\n",
      "might've: 2\n",
      "siyu: 2\n",
      "else's: 2\n",
      "son's: 4\n",
      "poncho-type: 2\n",
      "someone's: 5\n",
      "petite-sized: 2\n",
      "mauve-ish: 2\n",
      "who've: 2\n",
      "flatte: 2\n",
      "un-button: 2\n",
      "skirt's: 2\n",
      "torsoed: 2\n",
      "everleigh: 2\n",
      "amadi: 3\n",
      "pant's: 2\n",
      "wedding-ish: 2\n",
      "hook-and: 2\n",
      "that'd: 2\n",
      "people's: 2\n",
      "pullover's: 2\n",
      "dolman-style: 2\n",
      "g's: 2\n",
      "hei-hei: 2\n",
      "flatttering: 2\n",
      "petties: 2\n",
      "joe's: 2\n",
      "terrycloth-like: 2\n",
      "material's: 2\n",
      "artist's: 2\n",
      "wiast: 2\n",
      "bluishgreen: 2\n",
      "crosswrap: 2\n"
     ]
    }
   ],
   "source": [
    "missing = Counter( \n",
    "    tok \n",
    "    for review in tokenized_reviews \n",
    "    for tok in review \n",
    "    if tok not in ft_model \n",
    ") \n",
    "\n",
    "print(\"Top OOV tokens:\", missing.most_common(10))\n",
    "print(\"All missing tokens:\")\n",
    "for token, count in missing.items():\n",
    "    print(f\"{token}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon inspecting the missing tokens, most are either **misspellings** (`ejans`, `eptite`, `swtr`) or **words containing apostrophes** (`\"would've\"`, `\"model's\"`), which FastText may not handle directly in this form.\n",
    "\n",
    "Given the very low OOV rate and the non-critical nature of most missing tokens, I choose not to apply additional corrections or manual filtering at this stage. The model is sufficiently robust for embedding generation without modification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Generate Unweighted FastText Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first embedding-based representation I build is the unweighted average of word vectors. In this approach, each review is represented by taking the mean of all the word embeddings found in the review.\n",
    "\n",
    "Concept Overview:\n",
    "- For every token in a review, I check if it exists in the pretrained FastText model.\n",
    "- If it does, I collect its 300-dimensional vector.\n",
    "- I then compute the simple average across all available word vectors in that review.\n",
    "- If a review contains no known tokens, I return a zero vector of the same dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_embedding(tokens, model):\n",
    "    vectors = [model[w] for w in tokens if w in model]\n",
    "    if not vectors:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "unweighted_embeds = np.array([avg_embedding(tokens, ft_model) for tokens in tokenized_reviews])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in one fixed-size vector per review, providing a straightforward way to capture the overall semantic meaning of the text without applying any weighting scheme.\n",
    "\n",
    "To confirm the structure of the result, I preview the first few embeddings from a sample review using FastText:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText token-wise vectors (first 8 dims, showing up to 5 tokens):\n",
      "\n",
      "armholes: [0.0003, -0.0838, -0.0788, -0.0090, 0.1114, 0.0431, -0.0207, -0.0507]\n",
      "bit: [-0.0657, -0.0629, -0.1529, 0.0636, 0.0471, 0.0937, 0.0748, -0.0786]\n",
      "oversized: [0.0227, -0.0610, -0.0377, 0.0574, 0.0435, -0.0276, 0.0018, -0.0600]\n",
      "older: [0.0349, 0.0054, 0.0081, 0.0161, 0.0178, -0.0276, -0.0159, -0.0264]\n",
      "woman: [0.1328, -0.0516, 0.0142, 0.0771, -0.0610, -0.0764, 0.0576, 0.0009]\n"
     ]
    }
   ],
   "source": [
    "def validator_token_embeddings(tokens, ft_model, dims=5, limit=5):\n",
    "    print(f\"FastText token-wise vectors (first {dims} dims, showing up to {limit} tokens):\\n\")\n",
    "    shown = 0\n",
    "    for token in tokens:\n",
    "        if token in ft_model:\n",
    "            vec = ft_model[token][:dims]\n",
    "            rounded = [f\"{v:.4f}\" for v in vec]\n",
    "            print(f\"{token}: [{', '.join(rounded)}]\")\n",
    "            shown += 1\n",
    "        else:\n",
    "            print(f\"{token}: [OOV]\")\n",
    "            shown += 1\n",
    "        if shown >= limit:\n",
    "            break\n",
    "\n",
    "test_idx = 42\n",
    "validator_token_embeddings(tokenized_reviews[test_idx], ft_model, dims=8, limit=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a sample output from index 42, demonstrating that all 5 selected tokens are recognized and mapped to meaningful vectors.\n",
    "\n",
    "After reviewing the output, the embeddings appear to be correctly computed. I will now proceed to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Generate TF-IDF Weighted FastText Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I improve on the simple averaging method by applying TF-IDF weighting to the word embeddings. The idea here is to give more importance to informative words while reducing the influence of very common ones.\n",
    "\n",
    "Concept Overview:\n",
    "- I first compute TF-IDF values for all tokens using the same vocabulary built in Task 1.\n",
    "- For each review, I look up the FastText embeddings of the tokens that appear in both the embedding model and the TF-IDF dictionary.\n",
    "- Each word vector is scaled by its corresponding IDF weight.\n",
    "- I then take the weighted average of these vectors to form the final review embedding.\n",
    "- If a review has no matching tokens, I assign a zero vector of the same dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use same vocab as before\n",
    "tfidf_vectorizer = TfidfVectorizer(vocabulary=vocab)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(reviews)\n",
    "idf_weights = dict(zip(tfidf_vectorizer.get_feature_names_out(), tfidf_vectorizer.idf_))\n",
    "\n",
    "def tfidf_weighted_embedding(tokens, model, idf_dict):\n",
    "    vectors = []\n",
    "    weights = []\n",
    "    for token in tokens:\n",
    "        if token in model and token in idf_dict:\n",
    "            vectors.append(model[token] * idf_dict[token])\n",
    "            weights.append(idf_dict[token])\n",
    "    if not vectors:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.sum(vectors, axis=0) / np.sum(weights)\n",
    "\n",
    "weighted_embeds = np.array([\n",
    "    tfidf_weighted_embedding(tokens, ft_model, idf_weights)\n",
    "    for tokens in tokenized_reviews\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This weighted representation captures both the semantic meaning of words and their relative importance across the entire set of reviews—leading to potentially more discriminative features for downstream classification.\n",
    "\n",
    "To confirm the structure of the result, I preview a few token embeddings with their corresponding TF-IDF weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Weighted token-wise vectors (first 8 dims, up to 5 tokens):\n",
      "\n",
      "armholes: [0.0017, -0.4834, -0.4545, -0.0519, 0.6426, 0.2486, -0.1194, -0.2924]  (weight: 5.7680)\n",
      "bit: [-0.2066, -0.1978, -0.4809, 0.2000, 0.1481, 0.2947, 0.2353, -0.2472]  (weight: 3.1453)\n",
      "oversized: [0.1243, -0.3339, -0.2064, 0.3142, 0.2381, -0.1511, 0.0099, -0.3285]  (weight: 5.4743)\n",
      "older: [0.2636, 0.0408, 0.0612, 0.1216, 0.1345, -0.2085, -0.1201, -0.1994]  (weight: 7.5538)\n",
      "woman: [0.8354, -0.3246, 0.0893, 0.4850, -0.3837, -0.4806, 0.3624, 0.0057]  (weight: 6.2909)\n"
     ]
    }
   ],
   "source": [
    "def validator_weighted_tokens(tokens, model, idf_dict, dims=5, limit=5):\n",
    "    print(f\"TF-IDF Weighted token-wise vectors (first {dims} dims, up to {limit} tokens):\\n\")\n",
    "    shown = 0\n",
    "    for token in tokens:\n",
    "        if token in model and token in idf_dict:\n",
    "            vec = model[token] * idf_dict[token]\n",
    "            rounded = [f\"{v:.4f}\" for v in vec[:dims]]\n",
    "            print(f\"{token}: [{', '.join(rounded)}]  (weight: {idf_dict[token]:.4f})\")\n",
    "            shown += 1\n",
    "        elif token in model:\n",
    "            print(f\"{token}: [valid token, missing IDF]\")\n",
    "            shown += 1\n",
    "        else:\n",
    "            print(f\"{token}: [OOV]\")\n",
    "            shown += 1\n",
    "        if shown >= limit:\n",
    "            break\n",
    "\n",
    "test_idx = 42\n",
    "validator_weighted_tokens(tokenized_reviews[test_idx], ft_model, idf_weights, dims=8, limit=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reviewing the output, the embeddings appear to be correctly computed. I will now proceed to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Save Outputs\n",
    "\n",
    "After generating the three types of document-level representations, I now save them into their required output formats. Each line in the output files corresponds to one review and starts with a #index followed by the data values, separated by commas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Bag-of-Words\n",
    "\n",
    "- Saves the sparse Bag-og-words representation to `count_vectors.txt`\n",
    "- Format: #reviewIndex,tokenIndex1:count1,tokenIndex2:count2,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sparse BoW counts\n",
    "with open(\"t2_outputs/count_vectors.txt\", \"w\") as f:\n",
    "    for i, row in enumerate(X_counts):\n",
    "        entries = [\n",
    "            f\"{idx}:{val}\"\n",
    "            for idx, val in zip(row.indices, row.data)\n",
    "        ]\n",
    "        f.write(f\"#\" + str(i) + \",\" + \",\".join(entries) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Unweighted Embeddings\n",
    "\n",
    "- Saves the average FastText embeddings to `unweighted_vectors.txt`\n",
    "- Format: #reviewIndex,val1,val2,...,val300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save unweighted FastText embeddings\n",
    "with open(\"t2_outputs/unweighted_vectors.txt\", \"w\") as f:\n",
    "    for i, vec in enumerate(unweighted_embeds):\n",
    "        vec_str = \",\".join(map(str, vec))\n",
    "        f.write(f\"#{i},{vec_str}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 Weighted Embeddings\n",
    "- Saves the TF_IDF weighted FastText embeddings to `weighted_vectors.txt`\n",
    "- Format: #reviewIndex,val1,val2,...,val300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weighted FastText embeddings\n",
    "with open(\"t2_outputs/weighted_vectors.txt\", \"w\") as f:\n",
    "    for i, vec in enumerate(weighted_embeds):\n",
    "        vec_str = \",\".join(map(str, vec))\n",
    "        f.write(f\"#{i},{vec_str}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon inspection, the file format meets all specified requirements and appears correctly structured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Clothing Review Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...... Sections and code blocks on buidling classification models based on different document feature represetations. \n",
    "Detailed comparsions and evaluations on different models to answer each question as per specification. \n",
    "\n",
    "<span style=\"color: red\"> You might have complex notebook structure in this section, please feel free to create your own notebook structure. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to perform the task...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Give a short summary and anything you would like to talk about the assessment tasks here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Couple of notes for all code blocks in this notebook\n",
    "- please provide proper comment on your code\n",
    "- Please re-start and run all cells to make sure codes are runable and include your output in the submission.   \n",
    "<span style=\"color: red\"> This markdown block can be removed once the task is completed. </span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gensim_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
